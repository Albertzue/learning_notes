1. Traditional learning processes build a new model for each new task, based on the available labeled data. This is because traditional machine learning algorithms assume training and test data come from the same feature space, and so if the data distribution changes, or the trained model is applied to a new dataset, users must retrain a newer model from scratch, even if attempting a similar task as the first model (e.g. sentiment analysis classifier of movie reviews versus song reviews). Transfer learning algorithms, however, takes already-trained models or networks as a starting point. It then applies that model’s knowledge gained in an initial source task or data (e.g. classifying movie reviews) towards a new, yet related, target task or data (e.g. classifying song reviews).

2. **multi-modal embedding model** is a type of foundation model that can processand understand both text and images.This
makes it suitable for powering a search application that handles queries containing both text and images.

3. **Text embedding model** This type of model is only designed to process text data, so it wouldn't be suitable for handling
image queries.
4. **Multi-modal generation model** This type of model is designed to generate text or images, not to search for them.
5. **Image generation model** This type of model is only designed to generate images, not to search for them.

### AWS Bedrock
6. **Temperature** This controls the randomness of the output, not the input prompt length.Temperature affects creativity, not
input size.
7. **Context window** This defines the maximum length of the input prompt the model can process. It directly limits how much
information can be included.
8. **Batch size** This is the number of prompts processed at once, affecting throughput, not individual prompt length. It's about processing multiple promptsefficiently.
9. **Model size** This relates to the model's overall capacity and complexity, not directly to the input prompt length. Size impacts performance, not input limits.
---

10. **Amazon SageMaker JumpStart** is specifically designed to help teams quickly deployand use foundation models (FMs) with the
following benefits:
```
Provides pre-trained models that can be deployed with just a few clicks
Allows deployment within your VPC for secure access
Includes popular foundation models from various providers
Offers fine-tuning capabilities for customization
Handles the infrastructure management automatically
```
### Which functionality does Amazon SageMaker Clarify provide (following are not right answers)
11. **Integrates a RAG workflow**: RAG workflowsare used for combining retrieved documents with model outputs, typically in language models, but this is not a function of SageMaker Clarify.
12. **Monitors the quality of ML models in production**: Monitoring model quality in production is handled bySageMaker Model
Monitor, notSageMaker Clarify.
13. **Documents critical details about ML models**: This functionality is part of Amazon SageMaker Model Cards, which documents model details for transparencyand compliance.
---

14.  Recall-Oriented Understudy for Gisting Evaluation(ROUGE technique） is for text summarization evaluation, not lending decisions
15.  **Confusion matrix** is a key metric forevaluating classification models. It providesa summary of the model's predictions, showing the true positive, false positive, true negative,and false negative counts
16. **Moderation APIs** can help screen the content generated by the chatbot to ensure that inappropriate or unwanted imagesare not returned to users.These APIs can identifyand filter out offensive,explicit, or harmful content before it's shown to the user
17. Amazon Bedrock providesa built-in option to enable invocation logging. This feature allows you to capture and store detailed logs for model invocations, including input and output data, which helps you monitor and analyze the performance and behavior of the model
18.  **BERT (Bidirectional Encoder Representations from Transformers)** is a language model designed to understand context in text by considering both the left and right sides of a word. BERT-based modelsare well-suited for filling in missing words in
19.  **Jailbreaking** refers to bypassing or disabling the security restrictions placed on a system
20.  **AWS AI Service Cards** are designed for pre-built AI services provided by AWS, not for custom ML models developed bya team.
21. you want to measure both the precision (correctness of answers) and recall (how well the
model retrieves the relevant information).The **F1 score** helps you achieve a balanced view of these two metrics, making it a
good choice forevaluating model accuracy in a fine-tuned large language model (LLM) for answering questions.

22. In Stable Diffusion, Classifier-Free Guidance (CFG) scale controls how strongly the model follows the text prompt versus generating freely (more randomness).
  A higher CFG scale means the model adheres more closely to the prompt, resulting in more specific and detailed images.
  A lower CFG scale introduces more randomness, leading to less relevant or vague outputs

23. **BERTScore** is specifically designed forevaluating text generation quality
24.
```
 Human-in-the-loop: Human review of generated outputsallows for filtering or modification of biased or toxic content after generation. Community vote distribution
 Data augmentation:This occurs during training, modifying the training data itself, not the generated outputs.
 Feature engineering: Also a training phase activity, focusing on input features, not generated content.
 Adversarial training: Used during training to improve robustness, not to filter post-generation content.
 ```
## new words
1. Hallucinations
2. Plagiarism
