1. Traditional learning processes build a new model for each new task, based on the available labeled data. This is because traditional machine learning algorithms assume training and test data come from the same feature space, and so if the data distribution changes, or the trained model is applied to a new dataset, users must retrain a newer model from scratch, even if attempting a similar task as the first model (e.g. sentiment analysis classifier of movie reviews versus song reviews). Transfer learning algorithms, however, takes already-trained models or networks as a starting point. It then applies that model’s knowledge gained in an initial source task or data (e.g. classifying movie reviews) towards a new, yet related, target task or data (e.g. classifying song reviews).

2. **multi-modal embedding model** is a type of foundation model that can processand understand both text and images.This
makes it suitable for powering a search application that handles queries containing both text and images.

3. **Text embedding model** This type of model is only designed to process text data, so it wouldn't be suitable for handling
image queries.
4. **Multi-modal generation model** This type of model is designed to generate text or images, not to search for them.
5. **Image generation model** This type of model is only designed to generate images, not to search for them.

### AWS Bedrock
6. **Temperature** This controls the randomness of the output, not the input prompt length.Temperature affects creativity, not
input size.
7. **Context window** This defines the maximum length of the input prompt the model can process. It directly limits how much
information can be included.
8. **Batch size** This is the number of prompts processed at once, affecting throughput, not individual prompt length. It's about processing multiple promptsefficiently.
9. **Model size** This relates to the model's overall capacity and complexity, not directly to the input prompt length. Size impacts performance, not input limits.
---

10. **Amazon SageMaker JumpStart** is specifically designed to help teams quickly deployand use foundation models (FMs) with the
following benefits:
```
Provides pre-trained models that can be deployed with just a few clicks
Allows deployment within your VPC for secure access
Includes popular foundation models from various providers
Offers fine-tuning capabilities for customization
Handles the infrastructure management automatically
```
### Which functionality does Amazon SageMaker Clarify provide (following are not right answers)
11. **Integrates a RAG workflow**: RAG workflowsare used for combining retrieved documents with model outputs, typically in language models, but this is not a function of SageMaker Clarify.
12. **Monitors the quality of ML models in production**: Monitoring model quality in production is handled by SageMaker Model
Monitor, notSageMaker Clarify.
13. **Documents critical details about ML models**: This functionality is part of Amazon SageMaker Model Cards, which documents model details for transparencyand compliance.
---

14.  Recall-Oriented Understudy for Gisting Evaluation(ROUGE technique） is for text summarization evaluation, not lending decisions
15.  **Confusion matrix** is a key metric forevaluating classification models. It providesa summary of the model's predictions, showing the true positive, false positive, true negative,and false negative counts
16. **Moderation APIs** can help screen the content generated by the chatbot to ensure that inappropriate or unwanted imagesare not returned to users.These APIs can identifyand filter out offensive,explicit, or harmful content before it's shown to the user
17. Amazon Bedrock providesa built-in option to enable invocation logging. This feature allows you to capture and store detailed logs for model invocations, including input and output data, which helps you monitor and analyze the performance and behavior of the model
18.  **BERT (Bidirectional Encoder Representations from Transformers)** is a language model designed to understand context in text by considering both the left and right sides of a word. BERT-based modelsare well-suited for filling in missing words in
19.  **Jailbreaking** refers to bypassing or disabling the security restrictions placed on a system
20.  **AWS AI Service Cards** are designed for pre-built AI services provided by AWS, not for custom ML models developed bya team.
21. you want to measure both the precision (correctness of answers) and recall (how well the
model retrieves the relevant information).The **F1 score** helps you achieve a balanced view of these two metrics, making it a
good choice forevaluating model accuracy in a fine-tuned large language model (LLM) for answering questions.

22. In Stable Diffusion, Classifier-Free Guidance (CFG) scale controls how strongly the model follows the text prompt versus generating freely (more randomness).
  A higher CFG scale means the model adheres more closely to the prompt, resulting in more specific and detailed images.
  A lower CFG scale introduces more randomness, leading to less relevant or vague outputs

23. **BERTScore** is specifically designed forevaluating text generation quality
24.
```
 Human-in-the-loop: Human review of generated outputsallows for filtering or modification of biased or toxic content after generation. Community vote distribution
 Data augmentation:This occurs during training, modifying the training data itself, not the generated outputs.
 Feature engineering: Also a training phase activity, focusing on input features, not generated content.
 Adversarial training: Used during training to improve robustness, not to filter post-generation content.
 ```
25.
```
    Providing a set of examples before asking a question: Few-shot prompting
    Asking the model a question without providing examples: Zero-shot prompting
    Breaking down complex problems into logical steps: Chain-of-thought prompting
```
26. Which content categories can the guardrails filter：
      ```
      1. Hate
      2. Violence
      3. Sexual content
      4. Self-harm
      ```
27. **Prompt chaining** is a technique where a complex taskis broken down into smaller subtasks,and each subtaskis processed
sequentially bya large language model (LLM).The output of one step becomes the input to the next, forming a chain of
prompts.
28. Amazon SageMaker Model Monitor:
```
  Specifically designed to monitor model qualityand performance in production
  Detects data drift and model drift by comparing current predictionsagainst baseline statistics
  Automatically identifies changes in model accuracyand performance over time
  Provides real-time monitoring and alerting when model quality degrades
  Generates detailed reports on model performance metrics
  Can monitor multiple models simultaneously
  Integrates with CloudWatch for notificationsand automated responses
```
29. The company wants to improve the model’s domain knowledge by providing specific documents. is fine tuning not pre-training.Pretraining refers to training a model from scratch on a large dataset to learn general features and representations. It is notfocused on adapting to specific domain knowledge. Since the company already has a model and wants to improve its domainknowledge with specific documents, fine-tuning is the more suitable choice. Pretraining refers to training a model on a large general dataset before any specific task, which may not be as effective for domain-specific enhancements

30. Jumpstart offers prebuilt solutions - including fraud detection templatesand pretrained models you can deploy quickly.
31. Amazon Bedrockallows you to customize (fine-tune) foundation models securely without managing infrastructure. It is costeffective and fully managed,and the data remains in the AWS Region.
32. A Bilingual Evaluation Understudy (BLEU) score is an algorithm that measures the quality of machine-translated text by comparing it to one or more high-quality human translations.
33. Batch inference processes data in large batchesat scheduled intervals.
34.  Top K isa decoding parameter used during text generation by large language models (LLMs) that:
```
Limits the number of candidate next tokens to the top K most likely optionsat each step.
From this shortlist, the model samples one token, introducing controlled randomness.
Helps balance between coherence and diversity in output.
Forexample, if Top K = 50, the model will only consider the 50 most probable next tokensand randomly choose one based on
their probabilities
```
35. ReAct prompting (Reasoning and Acting) isa prompt engineering technique that:
```
Combines step-by-step reasoning (e.g.,analyzing a customer's request)
With actions, such as calling external tools or APIs, like inventory systems or product databases
Is ideal for use cases requiring real-time interaction with external data sources
```

36. Amazon SageMaker Ground Truth is designed specifically for:
```
  Data labeling at scale (including for computer vision tasks like image classification, object detection, etc.)
  Providing a user-friendly interface for annotators.
  Supporting human-in-the-loop workflows.
  Reducing labeling costs using active learning and automated labeling
```
37. **Model Shapley values** are a method from game theory used to explain the output of a machine learning model by fairly attributing the contribution of each input feature to a specific prediction
38. **AWS Bedrock PartyRock** is a space where you can build AI-generated apps in a playground powered by Amazon Bedrock. It's a fast and fun way to learn about generative AI.
39. Fine-tuning a foundation model involves providing labeled training data where each example consists of a prompt (the input to the model) and a completion (the desired output).This structure helps the model learn specific patterns or behaviors tailored to the company’s data and use case. In Amazon Bedrock, fine-tuning relies on a structured dataset that aligns with the model's learning requirements to improve its accuracy for domain-specific tasks.

38.
**Temperature**:This controls the randomness of the output, not the input prompt length.Temperature affects creativity, not
input size.
***Context window**:This defines the maximum length of the input prompt the model can process. It directly limits how much
information can be included.
**Batch size**:This is the number of prompts processed at once,affecting throughput, not individual prompt length. It's about
processing multiple promptsefficiently.
**Model size**:This relates to the model's overall capacityand complexity, not directly to the input prompt length.Size impacts performance, not input limits.

39. Amazon SageMakerServerless Inference allows you to deploy machine learning models in a fully managed, serverlessenvironment. You don't need to manage the underlying infrastructure (such asEC2 instances) to handle predictions.
40. AWS Artifact allows you to access AWS compliance reports,and it also includesa feature that sendsemail notifications when
new compliance documents become available. This feature directlyaddresses the company's need to receive notifications
when ISV compliance reportsare released.
41. Named entity recognition (NER) is a process in natural language processing that identifies and categorizes key information in text, such as names of people, organizations, and locations.
42. An Amazon Bedrock knowledge base allows you to incorporate your company's proprietary data into the foundation model. By
feeding the model with relevant information, you can enhance its ability to generate more accurate and informative responses.
43. Benchmark datasetsare specifically designed forevaluating models on specific tasks, including fairness
and bias.These datasets typically include a wide range of content and scenarios designed to assess how well the model
handles various forms of bias or discrimination. Using these datasets will provide the least administrative effort because they are pre-structured and widely recognized forevaluating model behavior acrossa variety of contexts

44. Set up inference for a custom model:
      ```
      1. Purchase Provisioned Throughput
      2. Deploy custom model for on-demand inference
      ```
45. Reinforcement learning: is the most suitable strategy for a chatbot to continuously improve its responses based on real-time feedbackfrom users.
46. Confusion matrix isa key metric forevaluating classification models. It providesa summary of the model's predictions,
showing the true positive, false positive, true negative,and false negative counts.
## new words

1. Hallucinations
2. Plagiarism
